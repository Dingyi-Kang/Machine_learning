# top tutorial (link: https://www.youtube.com/watch?v=BGiAcoU4yWk)
<img width="1483" alt="image" src="https://user-images.githubusercontent.com/81428296/188517364-aa8726da-707f-41f5-8926-aa06de774b31.png">
## 5 data points for example
<img width="1488" alt="image" src="https://user-images.githubusercontent.com/81428296/188517426-c55dfad3-3698-462c-ad43-0f63efca02c3.png">
<img width="1236" alt="image" src="https://user-images.githubusercontent.com/81428296/188517594-05dfa79c-75a9-4727-9d3d-5e34de9c3d53.png">
## then take a devirative of S with respect to theta. Given theta is not just one but a vector, the result derivrative is also a vector of quantity, which we use gradient operation to represent
### we got below using matrix caculus
<img width="1179" alt="image" src="https://user-images.githubusercontent.com/81428296/188517764-f0c584ac-6aef-4172-bb5a-b5245d085603.png">
## then we this gradient be 0
<img width="1385" alt="image" src="https://user-images.githubusercontent.com/81428296/188517849-7fc64328-5bd5-43c9-9c5e-f664977f37b6.png">

# However, this normal equation is seldom used in practive because of the matrix inverse involved, which is a nightmare for processor. Hence, this is analytic approach. In practice, we still use gradient descrent
# another problem of this soultion is this method is prone to the problem of overfitting. (take too much input and model is too complex)



# another tutorial: https://www.youtube.com/watch?v=1kkVEcmhkL8

<img width="1588" alt="image" src="https://user-images.githubusercontent.com/81428296/188516317-3aa72f4b-86e1-48d8-b69a-c1307c8e5cea.png">
<img width="848" alt="image" src="https://user-images.githubusercontent.com/81428296/188516338-fb389292-3445-494b-9da0-25e0c1be55a9.png">
<img width="393" alt="image" src="https://user-images.githubusercontent.com/81428296/188516350-320010cd-9188-4922-bd5f-cf27ae22d287.png">
<img width="1079" alt="image" src="https://user-images.githubusercontent.com/81428296/188516360-eb21daf4-7a58-4d53-85b4-c15b465a20cd.png">
<img width="405" alt="image" src="https://user-images.githubusercontent.com/81428296/188516373-a0c8ab54-c20b-481d-9489-269758bb5c26.png">
<img width="1642" alt="image" src="https://user-images.githubusercontent.com/81428296/188516393-772a27c6-af74-48aa-b1e3-fb416abf18d4.png">
<img width="1566" alt="image" src="https://user-images.githubusercontent.com/81428296/188516636-1d84b67b-5a04-4c73-988e-5a74c7dbd00b.png">
<img width="1508" alt="image" src="https://user-images.githubusercontent.com/81428296/188516754-0739f5d2-0b2e-4e2e-8adb-7e000d5c8204.png">

# Another great tutorial:
## below symbol means the gradient to J
<img width="722" alt="image" src="https://user-images.githubusercontent.com/81428296/188516874-6741c818-7371-4fa9-9272-6d1acca14bfd.png">
<img width="908" alt="image" src="https://user-images.githubusercontent.com/81428296/188516970-46e29561-9164-4221-9dd5-7d5e9366dce7.png">
